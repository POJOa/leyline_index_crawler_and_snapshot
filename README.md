# LeylineIndex Project    
![img](http://wx4.sinaimg.cn/large/005yrqtrgy1ffbqm6yk56j31kw0nq0ve.jpg)
 
## Purpose
To get familiar with several currently coolest field in I.T. , in order to make a "cityescape" from Web Development.    
## Naming
Leyline is the headlining name of my experimental projects , which stands for connected magics and miracles.    

## Roadmaps
   1. ☆[normal] Find available Chinese Personal weblogs using Broad-crawl (Finished with 950+ results)
   2. [easy] Build a platform to expose further data thru Web (Finished , URL : http://leyline.cc)    
   3. ☆☆[acceptable] Make a deep crawl of articles owned by specific sites and clean the data collected( **On-going** ).
   4. ☆☆☆[hardcore] Do some analysis using NLP or even Pattern Recognition , including emotional analysis and trending topics.
   5. ☆☆☆☆[nightmare] Expose structural data and try to build a workflow of 1,3,4 , consider to invite others to be part of this project.
   
# LeylineIndex Crawler
This repo is all about step 1 and 3 , powered by Scrapy.        

Well-formed website info presented in ./result.json     

Still working on deep-crawl txts , mentioned in the directory of spiders. ./crawl/scrap/spiders/*.json
    
./snapshot shows the process to automatically take snapshots of websites using Selenium.